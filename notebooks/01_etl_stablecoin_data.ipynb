{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e6757d",
   "metadata": {},
   "source": [
    "### Important:\n",
    "The data used in this exercise has already been cleaned. However, I included this notebook with a basic data cleaning step, as the process may vary depending on the context. For example, if the token is a stablecoin, it might be necessary to remove very small or very large values. Zero-value transactions could be relevant for identifying network activity, or they might indicate failed transactions or contract issues. Repeated values in short time spans may suggest arbitrage or testing behaviour. Therefore, the cleaning strategy should be adapted to the analysis goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "\n",
    "input_csv = '../data/token_transfers_V3.0.0.csv'\n",
    "output_csv = 'token_transfers_V3.0.0_cleaned.csv' # not used\n",
    "output_parquet = 'token_transfers_V3.0.0_cleaned.parquet'\n",
    "\n",
    "output_path = '../data/cleaned/'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excluded = pd.DataFrame()\n",
    "\n",
    "# standardise addresses in lower case\n",
    "df['from_address'] = df['from_address'].str.lower()\n",
    "df['to_address'] = df['to_address'].str.lower()\n",
    "df['contract_address'] = df['contract_address'].str.lower()\n",
    "\n",
    "# Simple validation - Ethereum\n",
    "def is_valid_eth_address(addr):\n",
    "    return isinstance(addr, str) and re.fullmatch(r\"0x[a-f0-9]{40}\", addr) is not None\n",
    "\n",
    "# Rename timestamp\n",
    "df.rename(columns={'time_stamp': 'timestamp'}, inplace=True)\n",
    "df['timestamp'] = df['timestamp'].astype(int)\n",
    "\n",
    "# Convert to date format\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "# Remove lines with missing essential data\n",
    "essential_cols = ['block_number', 'transaction_index', 'from_address', 'to_address', 'timestamp', 'contract_address', 'value']\n",
    "missing_rows = df[df[essential_cols].isnull().any(axis=1)]\n",
    "df_excluded = pd.concat([df_excluded, missing_rows])\n",
    "df.drop(index=missing_rows.index, inplace=True)\n",
    "\n",
    "# Remove negative values\n",
    "negative_values = df[df['value'] < 0]\n",
    "df_excluded = pd.concat([df_excluded, negative_values])\n",
    "df.drop(index=negative_values.index, inplace=True)\n",
    "\n",
    "# Remove invalid addresses\n",
    "invalid_from = df[~df['from_address'].apply(is_valid_eth_address)]\n",
    "invalid_to = df[~df['to_address'].apply(is_valid_eth_address)]\n",
    "invalid_contract = df[~df['contract_address'].apply(is_valid_eth_address)]\n",
    "invalid_rows = pd.concat([invalid_from, invalid_to, invalid_contract]).drop_duplicates()\n",
    "df_excluded = pd.concat([df_excluded, invalid_rows])\n",
    "df.drop(index=invalid_rows.index, inplace=True)\n",
    "\n",
    "# final\n",
    "n_total = len(df) + len(df_excluded)\n",
    "print(f\"Total original: {n_total}\")\n",
    "print(f\"Valids: {len(df)}\")\n",
    "print(f\"Excludeds: {len(df_excluded)}\")\n",
    "print(f\"Tax of validation: {(len(df) / n_total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptive statistics\n",
    "print(\"Descriptive:\")\n",
    "print(df['value'].describe())\n",
    "print(f\"\\nPerccentiles: {df['value'].quantile([0.001, 0.01, 0.05, 0.95, 0.99, 0.999])}\")\n",
    "\n",
    "# Identify imposible values\n",
    "test_values = df[df['value'] >= 1e15]\n",
    "print(f\"\\nExtreme values (>= 1e15): {len(test_values)}\")\n",
    "\n",
    "# Analisys per contract\n",
    "print(\"\\nAnalisys per contract:\")\n",
    "for contract in df['contract_address'].value_counts().head(5).index:\n",
    "    contract_data = df[df['contract_address'] == contract]\n",
    "    print(f\"{str(contract)[:10]}...: min={contract_data['value'].min():.4f}, max={contract_data['value'].max():.4f}\")\n",
    "\n",
    "# Remove outliers\n",
    "q_high = df['value'].quantile(0.9999) # 99.99%\n",
    "q_low = df['value'].quantile(0.0001) # 0.01%\n",
    "\n",
    "outlier_high = df[df['value'] > q_high]\n",
    "outlier_low = df[df['value'] < q_low]\n",
    "\n",
    "print(f\"\\nHighest outliers (> {q_high:.2f}): {len(outlier_high)}\")\n",
    "print(f\"Lowest outliers (< {q_low:.2f}): {len(outlier_low)}\")\n",
    "\n",
    "# Remove and update tracking\n",
    "df_excluded = pd.concat([df_excluded, outlier_high, outlier_low])\n",
    "df = df[(df['value'] >= q_low) & (df['value'] <= q_high)]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nAfter outliers removal: {len(df)} valid transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fb913",
   "metadata": {},
   "source": [
    "Direct links for mapping\n",
    "\n",
    "USDT (Tether)\n",
    "https://etherscan.io/token/0xdac17f958d2ee523a2206206994597c13d831ec7\n",
    "\n",
    "USDC (USD Coin)\n",
    "https://etherscan.io/token/0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\n",
    "\n",
    "DAI (Multi-Collateral DAI)\n",
    "https://etherscan.io/token/0x6b175474e89094c44da98b954eedeac495271d0f\n",
    "\n",
    "UST (TerraClassicUSD)\n",
    "https://etherscan.io/token/0xa47c8bf37f92abed4a126bda807a7b7498661acd\n",
    "\n",
    "PAX (Pax Dollar)\n",
    "https://etherscan.io/token/0x8e870d67f660d95d5be530380d0ec0bd388289e1\n",
    "\n",
    "WLUNA (Wrapped LUNA Classic)\n",
    "https://etherscan.io/token/0xd2877702675e6ceb975b4a1dff9fb7baf4c91ea9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map contract address to token names\n",
    "contract_to_token = {\n",
    "    '0xdac17f958d2ee523a2206206994597c13d831ec7': 'USDT',\n",
    "    '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48': 'USDC',\n",
    "    '0x6b175474e89094c44da98b954eedeac495271d0f': 'DAI',\n",
    "    '0xa47c8bf37f92abed4a126bda807a7b7498661acd': 'UST',\n",
    "    '0x8e870d67f660d95d5be530380d0ec0bd388289e1': 'PAX',\n",
    "    '0xd2877702675e6ceb975b4a1dff9fb7baf4c91ea9': 'WLUNA'\n",
    "}\n",
    "\n",
    "\n",
    "df['stablecoin'] = df['contract_address'].map(contract_to_token)\n",
    "df = df[~df['stablecoin'].isnull()]\n",
    "\n",
    "print(f\"Contract Addresses: {df['contract_address'].unique()}\")\n",
    "print(f\"\\nStablecoin: {df['stablecoin'].unique()}\")\n",
    "\n",
    "\n",
    "df.to_parquet(os.path.join(output_path, output_parquet), engine='pyarrow', index=False)\n",
    "\n",
    "print()\n",
    "df.info()\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
