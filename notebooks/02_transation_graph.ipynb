{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cba6d9b",
   "metadata": {},
   "source": [
    "This notebook constructs daily directed transaction graphs for each stablecoin based on cleaned ERC20 transfer data. Each node represents a wallet address, and each directed edge represents a token transfer between addresses, weighted by the transferred amount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a939d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "input_file = '../data/cleaned/token_transfers_cleaned.csv'\n",
    "output_dir = '../data/graphs/daily'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Loop over tokens and dates to build daily graphs\n",
    "for stablecoin in df['stablecoin'].unique():\n",
    "    df_stablecoin = df[df['stablecoin'] == stablecoin]\n",
    "    \n",
    "    for date in df_stablecoin['date'].unique():\n",
    "        df_day = df_stablecoin[df_stablecoin['date'] == date]\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        for _, row in df_day.iterrows():\n",
    "            u = row['from_address']\n",
    "            v = row['to_address']\n",
    "            w = row['value']\n",
    "            if G.has_edge(u, v):\n",
    "                G[u][v]['weight'] += w\n",
    "            else:\n",
    "                G.add_edge(u, v, weight=w)\n",
    "        \n",
    "        # Save graph with pickle\n",
    "        filename = f\"{stablecoin}_{date}.gpickle\"\n",
    "        path = os.path.join(output_dir, filename)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(G, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cfd6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DAI: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s]\n",
      "Processing PAX: 100%|██████████| 10/10 [00:00<00:00, 95.10it/s]\n",
      "Processing USDC: 100%|██████████| 10/10 [00:02<00:00,  4.72it/s]\n",
      "Processing USDT: 100%|██████████| 10/10 [00:03<00:00,  2.62it/s]\n",
      "Processing UST: 100%|██████████| 10/10 [00:00<00:00, 83.23it/s]\n",
      "Processing WLUNA: 100%|██████████| 10/10 [00:00<00:00, 98.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = '../data/graphs/daily'\n",
    "output_dir = '../data/graphs/metrics'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List .gpickle files\n",
    "gpickle_files = [f for f in os.listdir(input_dir) if f.endswith('.gpickle')]\n",
    "\n",
    "# Group files per stablecoin\n",
    "token_files = {}\n",
    "for file in gpickle_files:\n",
    "    if '_' in file:\n",
    "        token = file.split('_')[0]\n",
    "        token_files.setdefault(token, []).append(file)\n",
    "\n",
    "# Loop por stablecoin\n",
    "for token, files in token_files.items():\n",
    "    records = []\n",
    "\n",
    "    for file in tqdm(files, desc=f'Processing {token}'):\n",
    "        path = os.path.join(input_dir, file)\n",
    "\n",
    "        # Load Graph with pickle\n",
    "        with open(path, 'rb') as f:\n",
    "            G = pickle.load(f)\n",
    "\n",
    "        date = file.replace(f'{token}_', '').replace('.gpickle', '')\n",
    "\n",
    "        # The metrics\n",
    "        in_degrees = dict(G.in_degree())\n",
    "        out_degrees = dict(G.out_degree())\n",
    "        pagerank = nx.pagerank(G, alpha=0.85)\n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "        for node in G.nodes():\n",
    "            records.append({\n",
    "                'date': date,\n",
    "                'address': node,\n",
    "                'in_degree': in_degrees.get(node, 0),\n",
    "                'out_degree': out_degrees.get(node, 0),\n",
    "                'pagerank': pagerank.get(node, 0),\n",
    "                'degree_centrality': degree_centrality.get(node, 0)\n",
    "            })\n",
    "\n",
    "    # Save metrics per stablecoin\n",
    "    df_metrics = pd.DataFrame(records)\n",
    "    df_metrics.to_csv(os.path.join(output_dir, f'{token}_metrics.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: ../data/graphs/all_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "input_dir = '../data/graphs/metrics'\n",
    "output_file = '../data/graphs/all_metrics.csv'\n",
    "\n",
    "# Find all metric files\n",
    "metric_files = glob(os.path.join(input_dir, '*_metrics.csv'))\n",
    "\n",
    "# Store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "for file in metric_files:\n",
    "    token = os.path.basename(file).split('_')[0]\n",
    "    df = pd.read_csv(file)\n",
    "    df['token'] = token\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate Dataframes\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_all.to_csv(output_file, index=False)\n",
    "print(f\"Salvo em: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25601468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               event   timestamp      type  \\\n",
      "0  BlackRock and Fidelity Back USDC in $400 Milli...  1649721600  positive   \n",
      "1  Terra UST takes over BUSD to become third larg...  1650412800  positive   \n",
      "2  LARGE amounts of UST selling on ANCHOR (approx...  1651881600  negative   \n",
      "3  UST depegs LFG deploys assets to defend peg (7...  1651968000  negative   \n",
      "4    UST Depegs again to 35 cents LUNA keeps falling  1652054400  negative   \n",
      "\n",
      "  stablecoin        date  \n",
      "0       usdc  2022-04-12  \n",
      "1       ustc  2022-04-20  \n",
      "2       ustc  2022-05-07  \n",
      "3       ustc  2022-05-08  \n",
      "4       ustc  2022-05-09  \n",
      "Empty DataFrame\n",
      "Columns: [date, address, in_degree, out_degree, pagerank, degree_centrality, token]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Carrega os eventos\n",
    "event_df = pd.read_csv('../data/event_data.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "# Converte timestamp para date (formato YYYY-MM-DD)\n",
    "event_df['date'] = pd.to_datetime(event_df['timestamp'], unit='s').dt.date\n",
    "\n",
    "# Visualiza\n",
    "print(event_df.head())\n",
    "\n",
    "# Carrega as métricas\n",
    "metrics_df = pd.read_csv('../data/graphs/all_metrics.csv')\n",
    "metrics_df['date'] = pd.to_datetime(metrics_df['date']).dt.date  # garante formato compatível\n",
    "\n",
    "# Seleciona o primeiro evento como exemplo\n",
    "event = event_df.iloc[0]\n",
    "event_token = event['stablecoin'].upper()  # Ex: 'usdc' → 'USDC'\n",
    "event_date = event['date']\n",
    "\n",
    "\n",
    "metrics_df['token'] = metrics_df['token'].str.upper()\n",
    "event_df['stablecoin'] = event_df['stablecoin'].str.upper()\n",
    "\n",
    "# Filtra métricas por token e data do evento\n",
    "snapshot = metrics_df[(metrics_df['token'] == event_token) & (metrics_df['date'] == event_date)]\n",
    "\n",
    "print(snapshot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "050dcd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAI' 'PAX' 'USDC' 'USDT' 'UST']\n",
      "['usdc' 'ustc' 'lunaterra' 'usdt' 'unknown' 'dai']\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df['token'].unique())\n",
    "print(event_df['stablecoin'].unique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
